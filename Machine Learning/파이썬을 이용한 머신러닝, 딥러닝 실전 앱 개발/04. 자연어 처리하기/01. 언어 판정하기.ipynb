{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b4860f",
   "metadata": {},
   "source": [
    "## 언어 판정\n",
    "- 어떤 언어로 작성됐는지 판정하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417c53d",
   "metadata": {},
   "source": [
    "## 머신러닝으로 언어 판정 해보기\n",
    "- 문자를 구성하는 글자로 판정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c9e2f",
   "metadata": {},
   "source": [
    "### 언어 판정에 Unicode 코드 포인트 사용\n",
    "- Unicode 코드 포인트를 인덱스로 하는 배열을 만든다. (0~65535(FFFF) 등)\n",
    "- 배열의 각 요소는 대응하는 Unicode 코드 포인트의 출현 빈도로 초기값은 0\n",
    "- 문자 내부의 각 문자를 Unicode 코드 포인트로 변환하고 출현 빈도값을 더함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c4688",
   "metadata": {},
   "source": [
    "### 알고리즘 선택하기\n",
    "- 텍스트 데이터의 경우 나이브 베이즈(Naive Bayes) 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf4327",
   "metadata": {},
   "source": [
    "### 사용하는 문자가 다른 언어 판정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee136614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ko' 'ja' 'en']\n",
      "정답률 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Unicode 코드 포인트 출현 빈도 판정\n",
    "def count_codePoint(str):\n",
    "    # Unicode 코드 포인트를 저장할 배열\n",
    "    counter = np.zeros(65535)\n",
    "    \n",
    "    for i in range(len(str)):\n",
    "        # 각 문자를 Unicode 코드 포인트로 변환\n",
    "        code_point = ord(str[i])\n",
    "        if code_point > 65535:\n",
    "            continue\n",
    "        # 출현 횟수 세기\n",
    "        counter[code_point] += 1\n",
    "    \n",
    "    # 각 요소를 문자 수로 나눠 정규화\n",
    "    counter = counter / len(str)\n",
    "    return counter\n",
    "\n",
    "# 학습 전용 데이터 준비하기\n",
    "ko_str = '이것은 한국어 문장입니다.'\n",
    "ja_str = 'これは日本語の文章です。'\n",
    "en_str = 'This is English Sentences.'\n",
    "\n",
    "x_train = [count_codePoint(ko_str), count_codePoint(ja_str), count_codePoint(en_str)]\n",
    "y_train = ['ko', 'ja', 'en']\n",
    "\n",
    "# 학습\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 평가 전용 데이터 준비하기\n",
    "ko_test_str = '안녕하세요'\n",
    "ja_test_str = 'こんにちは'\n",
    "en_test_str = 'Hello'\n",
    "\n",
    "x_test = [count_codePoint(ko_test_str), count_codePoint(ja_test_str), count_codePoint(en_test_str)]\n",
    "y_test = ['ko', 'ja', 'en']\n",
    "\n",
    "# 평가\n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print('정답률 :', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca687fe6",
   "metadata": {},
   "source": [
    "### 사용하는 문자가 같은 언어 판정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057dc733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'en' 'es']\n",
      "정답률 : 1.0\n",
      "Wall time: 344 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "\n",
    "# Unicode 코드 포인트 출현 빈도 판정\n",
    "def count_codePoint(str):\n",
    "    # Unicode 코드 포인트를 저장할 배열\n",
    "    counter = np.zeros(65535)\n",
    "    \n",
    "    for i in range(len(str)):\n",
    "        # 각 문자를 Unicode 코드 포인트로 변환\n",
    "        code_point = ord(str[i])\n",
    "        if code_point > 65535:\n",
    "            continue\n",
    "        # 출현 횟수 세기\n",
    "        counter[code_point] += 1\n",
    "    \n",
    "    # 각 요소를 문자 수로 나눠 정규화\n",
    "    counter = counter / len(str)\n",
    "    return counter\n",
    "\n",
    "# 학습 데이터\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for file in glob.glob('../datasets/lang/train/*.txt'):\n",
    "    # 언어 정보를 추출하고 레이블로 저장\n",
    "    y_train.append(file[23:25])\n",
    "    \n",
    "    # 파일 내부의 문자열을 모두 추출한 뒤 빈도 배열로 변환, 입력데이터로 사용\n",
    "    file_str = ''\n",
    "    for line in open(file, 'r', encoding='utf8'):\n",
    "        file_str = file_str + line\n",
    "    x_train.append(count_codePoint(file_str))\n",
    "\n",
    "# 학습\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 평가 데이터\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for file in glob.glob('../datasets/lang/test/*.txt'):\n",
    "    # 언어 정보를 추출하고 레이블로 저장\n",
    "    y_test.append(file[22:24])\n",
    "    \n",
    "    # 파일 내부의 문자열을 모두 추출한 뒤 빈도 배열로 변환, 입력데이터로 사용\n",
    "    file_str = ''\n",
    "    for line in open(file, 'r', encoding='utf8'):\n",
    "        file_str = file_str + line\n",
    "    x_test.append(count_codePoint(file_str))\n",
    "\n",
    "# 평가\n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print('정답률 :', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c23b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
