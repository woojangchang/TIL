{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a34ba96",
   "metadata": {},
   "source": [
    "## 단어 벡터\n",
    "- 단어의 의미 또는 유사도 계산\n",
    "- Word Embeddings라고 부르기도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209cb44",
   "metadata": {},
   "source": [
    "## 단어의 의미를 벡터로 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c8e51",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "- Google 연구자 토머스 미코로프가 만든 방법\n",
    "- 딥러닝 기술을 사용해 단어를 벡터로 만드는 방법\n",
    "    - 단어는 주변의 단어들과 관계가 있다는 점에 착안하여 의미를 추축\n",
    "    - 약점은 반대되는 의미를 가진 단어를 비슷한 벡터로 표현 (좋다, 싫다 등)\n",
    "- Skip-gram, CBOW가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6dcff",
   "metadata": {},
   "source": [
    "### 코퍼스\n",
    "- 목적에 맞게 적절한 문장을 학습시켜야 함\n",
    "- '존나'의 경우, 과거에는 부정적인 느낌이었으나 최근에는 아님\n",
    "- 코퍼스 : 모델을 만들기 위한 대량의 띄어쓰기로 구분된 데이터를 포함하여, 컴퓨터로 검색이 가능한 대량의 언어 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6983e9a",
   "metadata": {},
   "source": [
    "### 코퍼스 생성하기\n",
    "- [위키피디아(한국어) 데이터](https://dumps.wikimedia.org/kowiki/latest/) - [kowiki-latest-pages-articles.xml.bz2](https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-articles.xml.bz2)\n",
    "- Docker 등 linux 명령 프롬프트 창을 이용하여 압축 풀기  \n",
    "    `bzip2 -d kowiki-latest-pages-articles.xml.bz2`\n",
    "- Ruby 설치\n",
    "- wp2txt 설치  \n",
    "    `gem install wp2txt`\n",
    "- XML to txt  \n",
    "    `wp2txt --input-file ./kowiki-latest-pages-articles.xml`\n",
    "- 분리된 텍스트 파일을 하나의 파일로 뭉치기  \n",
    "    `cat kowiki-latest-pages-articles-* > wiki.wp2txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e22982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current - 0\n",
      "current - 1000000\n",
      "current - 2000000\n",
      "current - 3000000\n",
      "current - 4000000\n",
      "current - 5000000\n",
      "current - 6000000\n",
      "current - 7000000\n",
      "current - 8000000\n",
      "current - 9000000\n",
      "current - 10000000\n",
      "current - 11000000\n",
      "current - 12000000\n",
      "current - 13000000\n",
      "current - 14000000\n",
      "current - 15000000\n",
      "current - 16000000\n",
      "current - 17000000\n",
      "current - 18000000\n",
      "current - 19000000\n",
      "current - 20000000\n",
      "current - 21000000\n",
      "current - 22000000\n",
      "current - 23000000\n",
      "Wall time: 4h 33min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import codecs\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# 파일 열기\n",
    "readFp = codecs.open('../datasets/wiki.wp2txt', 'r', encoding='utf8')\n",
    "gubun_file = '../datasets/wiki.gubun'\n",
    "writeFp = open(gubun_file, 'w', encoding='utf8')\n",
    "\n",
    "# 형태소 분석\n",
    "okt = Okt()\n",
    "i = 0\n",
    "# 텍스트 한 줄씩 처리\n",
    "while True:\n",
    "    line = readFp.readline()\n",
    "    if not line: break\n",
    "    if i%1000000 == 0:\n",
    "        print('current -', i)\n",
    "    i += 1\n",
    "    \n",
    "    # 형태소 분석\n",
    "    malist = okt.pos(line, norm=True, stem=True)\n",
    "    \n",
    "    # 필요한 어구만 대상으로 하기\n",
    "    for word in malist:\n",
    "        # 어미/조사/구두점 제외\n",
    "        if not word[1] in ['Josa', 'Eomi', 'Punctuation']:\n",
    "            writeFp.write(word[0] + ' ')\n",
    "writeFp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e840c61",
   "metadata": {},
   "source": [
    "결과 : 23,000,000+, 4시간 30분, 1.06GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf8940",
   "metadata": {},
   "source": [
    "### 자연어 처리 라이브러리 Gensim\n",
    "- 주제 분석 등 자연어 처리 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d836a3",
   "metadata": {},
   "source": [
    "### 모델 만들기\n",
    "- `gensim.models.word2vec.Word2Vec(sentences, sg, vector_size, window)` : 모델 생성\n",
    "    - `sg` : Word2Vec에서 사용할 알고리즘으로 1=Skip-gram, 0=CBOW\n",
    "    - `vector_size` : 벡터의 차원 설정. 100~200 정도를 설정하는 것이 일반적이지만, 숫자가 늘어날수록 오랜 시간이 걸림\n",
    "    - `window` : 학습할 단어를 연관시킬 앞뒤의 단어 수 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad31a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 코퍼스 읽어 들이기\n",
    "sentences = word2vec.Text8Corpus('../datasets/wiki.gubun')\n",
    "\n",
    "# 모델 만들기\n",
    "model = word2vec.Word2Vec(sentences, sg=1, vector_size=200, window=5)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('../models/wiki.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc9a85",
   "metadata": {},
   "source": [
    "### 모델을 사용해 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a521c",
   "metadata": {},
   "source": [
    "#### 유의어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2df21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('과자류', 0.7754049897193909)\n",
      "('화과자', 0.7620612978935242)\n",
      "('주먹밥', 0.7221462726593018)\n",
      "('덴푸라', 0.7182508111000061)\n",
      "('계란말이', 0.7110555171966553)\n",
      "('젤라또', 0.7085745334625244)\n",
      "('케이크', 0.7069568037986755)\n",
      "('사탕', 0.7049573659896851)\n",
      "('군것질', 0.7046226859092712)\n",
      "('디저트', 0.7035354375839233)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load('../models/wiki.model')\n",
    "results = model.wv.most_similar(positive=['과자'])\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed47203",
   "metadata": {},
   "source": [
    "#### 반의어?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da415693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('왕세자', 0.6083212494850159)\n",
      "('왕비', 0.5947650074958801)\n",
      "('1394~1460', 0.5590384006500244)\n",
      "('아브틴', 0.5570813417434692)\n",
      "('왕녀', 0.5559399724006653)\n",
      "('코넛', 0.550190269947052)\n",
      "('공주', 0.5485385060310364)\n",
      "('여왕', 0.5427746176719666)\n",
      "('1398~1479', 0.5278303623199463)\n",
      "('스트래선', 0.523162305355072)\n"
     ]
    }
   ],
   "source": [
    "results = model.wv.most_similar(positive=['왕자', '여성'], negative=['남성'])\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890febc",
   "metadata": {},
   "source": [
    "#### 문장 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1252ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터에 문제가 생겼어요. 빨리 해결해야 하는 문제가 있어서 지원 요청합니다.\n",
      "- 컴퓨터 : 0.0993922\n",
      "- 문제 : 0.35688016\n",
      "- 생기다 : 0.38950863\n",
      "- 빨리 : 0.5986096\n",
      "- 해결 : 0.3844186\n",
      "- 하다 : 0.38777393\n",
      "- 하다 : 0.38777393\n",
      "- 문제 : 0.35688016\n",
      "- 있다 : 0.34192967\n",
      "- 지원 : 0.27302924\n",
      "- 요청 : 0.43129143\n",
      "- 하다 : 0.38777393\n",
      "사용 방법을 잘 모르겠습니다.\n",
      "- 사용 : 0.23760146\n",
      "- 방법 : 0.2737294\n",
      "- 자다 : 0.29164606\n",
      "- 모르다 : 0.32622546\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 모델 읽어 들이고 형태소 분석 준비\n",
    "model = word2vec.Word2Vec.load('../models/wiki.model')\n",
    "okt = Okt()\n",
    "\n",
    "def print_emargency(text):\n",
    "    print(text)\n",
    "    # 전달된 문장을 형태소 분석하기\n",
    "    node = okt.pos(text, norm=True, stem=True)\n",
    "    for word, form in node:\n",
    "        # 필요한 형태소만 추출\n",
    "        if form == 'Noun' or form == 'Verb' or form == 'Adjective' or form == 'Adverb':\n",
    "            # 급하다와 비슷한 단어\n",
    "            print('-', word, ':', model.wv.similarity(word, '급하다'))\n",
    "            \n",
    "print_emargency('컴퓨터에 문제가 생겼어요. 빨리 해결해야 하는 문제가 있어서 지원 요청합니다.')\n",
    "print_emargency('사용 방법을 잘 모르겠습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b876e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
