{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9afaaf8",
   "metadata": {},
   "source": [
    "## 동영상 분석\n",
    "- OpenCV를 통해 웹 카메라로부터의 입력 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56250ad3",
   "metadata": {},
   "source": [
    "### 웹 카메라 이미지를 실시간으로 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d4f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 웹 카메라로부터 입력 받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # 카메라 이미지 읽어 들이기\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    # 이미지 축소해서 출력하기\n",
    "    frame = cv2.resize(frame, (480, 270))\n",
    "    \n",
    "    # 윈도우에 출력하기\n",
    "    cv2.imshow('OpenCV Web Camera', frame)\n",
    "    \n",
    "    # ESC 또는 Enter 키 입력되면 종료\n",
    "    k = cv2.waitKey(1) # 1msec 대기\n",
    "    if k == 27 or k == 13:\n",
    "        break\n",
    "        \n",
    "cap.release() # 카메라 해제\n",
    "cv2.destroyAllWindows() # 윈도우 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5df67",
   "metadata": {},
   "source": [
    "### 카메라에서 붉은색 성분만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cfdc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 웹 카메라로부터 입력 받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # 이미지 추출\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    # 이미지 축소\n",
    "    frame = cv2.resize(frame, (480, 270))\n",
    "    \n",
    "    # 파란색, 녹색 없애기\n",
    "    # Blue, Green, Red 순\n",
    "    frame[:, :, 0] = 0 # Blue\n",
    "    frame[:, :, 1] = 0 # Green\n",
    "    \n",
    "    # 윈도우에 출력하기\n",
    "    cv2.imshow('Red Camera', frame)\n",
    "    \n",
    "    # ESC 또는 Enter 키 입력되면 종료\n",
    "    k = cv2.waitKey(1) # 1msec 대기\n",
    "    if k == 27 or k == 13:\n",
    "        break\n",
    "        \n",
    "cap.release() # 카메라 해제\n",
    "cv2.destroyAllWindows() # 윈도우 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764e60c",
   "metadata": {},
   "source": [
    "### HSV 색공간을 사용해 색 검출하기\n",
    "- Hue(색상), 붉은색>녹색>파란색>붉은색의 360도 원형으로 표현\n",
    "- Saturation(채도)\n",
    "- Value Brightness(명도)\n",
    "\n",
    "[HSV 색공간](https://ko.wikipedia.org/wiki/HSV_%EC%83%89_%EA%B3%B5%EA%B0%84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f4326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 웹 카메라로부터 입력 받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # 이미지 추출\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    # 이미지 축소\n",
    "    frame = cv2.resize(frame, (480, 270))\n",
    "    \n",
    "    # 색공간을 HSV로 변환\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV_FULL)\n",
    "    \n",
    "    # HSV 분할\n",
    "    h = hsv[:, :, 0]\n",
    "    s = hsv[:, :, 1]\n",
    "    v = hsv[:, :, 2]\n",
    "    \n",
    "    # 붉은색 가진 요소만 출력\n",
    "    img = np.zeros(h.shape, dtype=np.uint8)\n",
    "    img[((h < 50) | (h > 200)) & (s > 100)] = 255\n",
    "    \n",
    "    # 윈도우에 출력하기\n",
    "    cv2.imshow('Red Camera', img)\n",
    "    \n",
    "    # ESC 또는 Enter 키 입력되면 종료\n",
    "    k = cv2.waitKey(1) # 1msec 대기\n",
    "    if k == 27 or k == 13:\n",
    "        break\n",
    "        \n",
    "cap.release() # 카메라 해제\n",
    "cv2.destroyAllWindows() # 윈도우 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b970d5b",
   "metadata": {},
   "source": [
    "## 화면에 움직임이 있는 부분 추출하기\n",
    "- `cv2.absdiff()` 함수를 사용하여 이미지의 차이를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8600e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "img_last = None # 이전 프레임을 저장해둘 변수\n",
    "green = (0, 255, 0)\n",
    "\n",
    "while True:\n",
    "    # 이미지 추출\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (480, 270))\n",
    "    \n",
    "    # 흑백 이미지로 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    img_b = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    \n",
    "    # 차이 확인하기\n",
    "    if img_last is None:\n",
    "        img_last = img_b\n",
    "        continue\n",
    "    \n",
    "    frame_diff = cv2.absdiff(img_last, img_b)\n",
    "    cnts = cv2.findContours(frame_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    \n",
    "    # 차이가 있는 부분 출력하기\n",
    "    for pt in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(pt)\n",
    "        if w < 30 : continue\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), green, 2)\n",
    "    \n",
    "    # 프레임을 변수에 저장\n",
    "    img_last = img_b\n",
    "    \n",
    "    # 화면에 출력\n",
    "    cv2.imshow('Diff Camera', frame)\n",
    "    cv2.imshow('diff data', frame_diff)\n",
    "    if cv2.waitKey(1) == 13: break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea594a",
   "metadata": {},
   "source": [
    "## 이미지 파일 쓰기\n",
    "- `cv2.VideoWriter(filename, format, fps, size)` : 동영상 쓰기 전용 객체 생성\n",
    "    - `format` : 동영상 형식 지정\n",
    "        - `cv.VideoWriter_fourcc('m', 'p', '4', 'v')` : MPEG-4 Video를 나타내는 mp4v를 한 글자씩 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a816d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 카메라 입력 받기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 동영상 출력 전용 객체 생성\n",
    "fmt = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fps = 20.0\n",
    "size = (1920, 1080)\n",
    "writer = cv2.VideoWriter('../datasets/test.m4v', fmt, fps, size)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.resize(frame, size)\n",
    "    \n",
    "    # 이미지 출력 (영상에 저장)\n",
    "    writer.write(frame)\n",
    "    \n",
    "    # 화면에도 출력\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:break\n",
    "\n",
    "writer.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18de577",
   "metadata": {},
   "source": [
    "## 동영상에서 열대어가 나오는 부분 검출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c877c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "\n",
    "img_last = None # 이전 프레임 저장할 변수\n",
    "no = 0 # 이미지 장수\n",
    "save_dir = '../datasets/exfish' # 저장 디렉터리\n",
    "os.mkdir(save_dir) # 디렉터리 생성\n",
    "\n",
    "# 동영상 파일로부터 입력 받기\n",
    "cap = cv2.VideoCapture('../datasets/fish.mp4')\n",
    "while True:\n",
    "    # 이미지 추출\n",
    "    is_ok, frame = cap.read()\n",
    "    if not is_ok : break\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    \n",
    "    # 흑백 이미지로 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    img_b = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    \n",
    "    # 차이 확인\n",
    "    if not img_last is None:\n",
    "        frame_diff = cv2.absdiff(img_last, img_b)\n",
    "        cnts = cv2.findContours(frame_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        \n",
    "        # 차이가 있는 부분 파일로 출력\n",
    "        for pt in cnts:\n",
    "            x, y, w, h = cv2.boundingRect(pt)\n",
    "            if w < 100 or x > 500 : continue # 노이즈 제거\n",
    "            # 추출한 영역 저장\n",
    "            imgex = frame[y:y+h, x:x+w]\n",
    "            outfile = save_dir +'/' + str(no) + '.jpg'\n",
    "            cv2.imwrite(outfile, imgex)\n",
    "            no += 1\n",
    "    img_last = img_b\n",
    "cap.release()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa88b1",
   "metadata": {},
   "source": [
    "## 머신러닝으로 동영상에서 열대어가 많이 나오는 부분 찾기\n",
    "- 열대어가 나오는 이미지와 없는 이미지 분리하여 fish, nofish 디렉터리에 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6eed5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.9054593874833555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/fish.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# 이미지 학습 크기와 경로 지정\n",
    "image_size = (64, 32)\n",
    "path_fish = '../datasets/fish'\n",
    "path_nofish = '../datasets/nofish'\n",
    "x = [] # 이미지 데이터\n",
    "y = [] # 레이블 데이터\n",
    "\n",
    "# 이미지를 읽어 들이고 배열에 넣기\n",
    "def read_dir(path, label):\n",
    "    files = glob.glob(path + '/*.jpg')\n",
    "    for f in files:\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img, image_size)\n",
    "        img_data = img.reshape(-1, ) # 1차원으로 전개\n",
    "        x.append(img_data)\n",
    "        y.append(label)\n",
    "\n",
    "# 이미지 데이터 읽어 들이기\n",
    "read_dir(path_nofish, 0)\n",
    "read_dir(path_fish, 1)\n",
    "\n",
    "# train, test 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# 데이터 학습\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 정답률 확인\n",
    "y_pred = clf.predict(x_test)\n",
    "print('정확도 :', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 데이터 저장\n",
    "joblib.dump(clf, '../models/fish.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358f6a8",
   "metadata": {},
   "source": [
    "### 동영상 분석하기\n",
    "- 열대어가 많이 나오는 부분을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf1f24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 48 / 1990\n"
     ]
    }
   ],
   "source": [
    "import cv2, os, copy, joblib\n",
    "\n",
    "# 학습한 데이터 읽어 들이기\n",
    "clf = joblib.load('../models/fish.pkl')\n",
    "output_dir = '../datasets/bestshot'\n",
    "img_last = None\n",
    "fish_th = 3 # 이미지로 출력할 기준이 되는 물고기 수\n",
    "count = 0\n",
    "frame_count = 0\n",
    "if not os.path.isdir(output_dir) : os.mkdir(output_dir)\n",
    "\n",
    "# 동영상 파일 읽어 들이기\n",
    "cap = cv2.VideoCapture('../datasets/fish.mp4')\n",
    "while True:\n",
    "    # 이미지 추출\n",
    "    is_ok, frame = cap.read()\n",
    "    if not is_ok:break\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    frame2 = copy.copy(frame)\n",
    "    frame_count += 1\n",
    "    \n",
    "    # 이전 프레임과 비교를 위해 흑백으로 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    img_b = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    \n",
    "    if not img_last is None:\n",
    "        # 차이 추출\n",
    "        frame_diff = cv2.absdiff(img_last, img_b)\n",
    "        cnts = cv2.findContours(frame_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "        \n",
    "        # 차이가 있는 부분에 물고기가 있는지 확인\n",
    "        fish_count = 0\n",
    "        for pt in cnts:\n",
    "            x, y, w, h = cv2.boundingRect(pt)\n",
    "            if w < 100 or x > 500 : continue # 노이즈 제거\n",
    "            # 추출한 영역에 물고기가 있는지 확인\n",
    "            imgex = frame[y:y+h, x:x+w]\n",
    "            imagex = cv2.resize(imgex, (64, 32))\n",
    "            img_data = imagex.reshape(-1, )\n",
    "            pred_y = clf.predict([img_data])\n",
    "            if pred_y[0] == 1:\n",
    "                fish_count += 1\n",
    "                cv2.rectangle(frame2, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "        # 물고기가 많이 있는지 확인\n",
    "        if fish_count > fish_th:\n",
    "            fname = output_dir + '/fish' + str(count) + '.jpg'\n",
    "            cv2.imwrite(fname, frame)\n",
    "            count += 1\n",
    "            \n",
    "    cv2.imshow('FISH!', frame2)\n",
    "    if cv2.waitKey(1) == 13:break\n",
    "    img_last = img_b\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('ok', count, '/', frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c31d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
