{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9093969d",
   "metadata": {},
   "source": [
    "# 1.1 인공 지능과 머신 러닝, 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bfaf47",
   "metadata": {},
   "source": [
    "## 1.1.1 인공 지능\n",
    "- 1950년대 \"컴퓨터가 '생각'할 수 있는가?\"라는 질문부터 시작\n",
    "- **보통의 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동**\n",
    "- AI는 머신 러닝과 딥러닝을 포괄하는 분야\n",
    "- **심볼릭 AI(Symbolic AI)** : 프로그래머들이 명시적인 규칙을 충분하게 많이 만들어 지식을 다루면 인간 수준의 인공 지능을 만들 수 있다는 접근 방식\n",
    "    - 1950년대~1980년대까지 AI 분야의 지배적인 패러다임\n",
    "    - 1980년대 **전문가 시스템**(Expert System)의 호황\n",
    "- 이미지 분류, 음성 인식, 언어 번역 등의 복잡하고 불분명한 문제 해결을 위하여 나온 새로운 방법이 **머신 러닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc065cb",
   "metadata": {},
   "source": [
    "## 1.1.2 머신 러닝\n",
    "- 에이다 러브레이스(Ada Lovelace) : 1843년 해석학 분야의 계산을 자동화하기 위한 해석 기관 발명\n",
    "    - 이 사람이 개발한 베르누이 수를 구하는 알고리즘이 최초의 프로그램으로 인정 받아 최초의 프로그래머로 불림\n",
    "- 앨런 튜링(Alan Turing) : 1950년 **튜링 테스트**와 AI의 주요 개념을 소개\n",
    "- 머신 러닝 : 명시적으로 프로그램되는 것이 아닌 **훈련**되는 것\n",
    "- 1990년대부터 각광을 받았으나 고성능 하드웨어와 대량의 데이터셋이 가능해진 최근 크게 성장\n",
    "- 통계와 밀접한 관계가 있으나 다른 점이 있음\n",
    "    - 대량의 복잡한 데이터셋을 다루기 때문에 베이지안 분석 같은 전통적 통계 분석 방법 적용이 힘듬\n",
    "    - 머신 러닝과 딥러닝은 수학적 이론이 부족하며 이론보다는 경험을 바탕으로 아이디어가 증명되는 경우가 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5cebc5",
   "metadata": {},
   "source": [
    "## 1.1.3 데이터에서 표현을 학습하기\n",
    "- 머신 러닝을 하귀 위해 필요한 세 가지\n",
    "    - 입력 데이터 포인트 : 주어진 문제에 대한 데이터 (음성 인식 - 음성 파일, 이미지 분류 - 이미지 파일)\n",
    "    - 기대 출력 : 태그 (음성 인식 - 글, 이미지 분류 - 개, 고양이 등의 분류)\n",
    "    - 알고리즘의 성능을 측정하는 방법 : 현재 출력과 기대 출력 간의 차이를 결정하기 위함\n",
    "        - **학습**(learning) : 측정값이 알고리즘의 작동 방식을 교정하기 위한 신호로 다시 피드백 되는 것\n",
    "- **의미 있는 데이터로의 변환**이 머신 러닝과 딥러닝의 핵심 문제\n",
    "    - 입력 데이터를 기반으로 기대 출력에 가깝게 만드는 유용한 **표현**(representation)을 학습하는 것\n",
    "- 머신 러닝 알고리즘은 **가설 공간**(hypothesis space)이라 부르는 미리 정의된 연산의 모음들을 자세히 조사하는 것뿐임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc192dc",
   "metadata": {},
   "source": [
    "## 1.1.4 딥러닝에서 '딥'이란 무엇일까?\n",
    "- 연속된 **층**(layer)이 깊다는 의미\n",
    "- **층 기반 표현 학습**(layered representations learning) 또는 **계층적 표현 학습**(hierarchical representation learning)이 더 적절한 이름일 수 있음\n",
    "- **얕은 학습**(shallow learning) : 다른 머신 러닝 기법은 1~2개의 데이터 표현 층\n",
    "- 기본 층을 겹겹이 쌓아 올려 구성한 **신경망**(neural network) 모델을 사용\n",
    "- 심층 신경망을 정보가 연속된 필터(filter)를 통과하면서 순도 높게(어떤 작업에 대해서 유용하게) 정제되는 다단계 정보 추출 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89697927",
   "metadata": {},
   "source": [
    "## 1.1.5 그림 3개로 딥러닝의 작동 원리 이해하기\n",
    "- 입력 데이터가 처리되는 상세 내용운 일련의 숫자로 이루어진 층의 **가중치**(weight)에 저장되어 있음\n",
    "    - 어떤 층에서 일어나는 변환은 그 층의 가중치를 **파라미터**(parameter)로 가지는 함수로 표현\n",
    "- **학습**(목표) : 주어진 입력을 정확한 타깃에 매핑하기 위해 신경망의 모든 층에 있는 가중치 값을 찾는 것\n",
    "- **손실 함수**(loss function) 또는 **목적 함수**(objective function) : 출력이 기대하는 것보다 얼마나 벗어났는가를 측정\n",
    "    - 수정 과정은 딥러닝의 핵심 알고리즘인 **역전파**(Backpropagation) 알고리즘을 구현한 **옵티마이터**(optimizer)가 담당\n",
    "- **훈련 반복**(training loop)를 거치면서 손실 함수를 최소화하는 가충치 값을 산출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c20bc",
   "metadata": {},
   "source": [
    "## 1.1.6 지금까지 딥러닝의 성과\n",
    "- 이미지 분류, 음성 인식, 필기 인식, 기계 번역, TTS 변환\n",
    "- 디지털 비서, 자율 주행, 광고 타기팅, 웹 검색 엔진\n",
    "- 자연어 질문에 대답하는 능력\n",
    "- 사람을 능가하는 바둑 실력 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5744d",
   "metadata": {},
   "source": [
    "## 1.1.7 단기간의 과대 선전을 믿지 말자\n",
    "- 사람 수준의 기계 번역, 사람 수준의 자연어 이해 등은 아직까지 어려운 문제\n",
    "- 특히 **일반 지능**(general intelligence)의 이야기는 심각하게 다루지 않는 것이 좋음\n",
    "- 1960년대 몇 년 안에 인간 지능 수준의 인공 지능이 나올 것이라 하였지만 기대에 미치지 못하자 투자가 줄어들어 첫 번째 **AI 겨울**(AI winter)이 시작됨\n",
    "- 1980년대 전문가 시스템이 인기를 끌자 많은 회사에서 이 기술에 많은 투자를 하였으나 한계를 보여 두 번째 AI 겨울이 시작됨\n",
    "- 그러므로 현대 AI 과대 선전과 실망의 사이클을 반복하지 않아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb96dd",
   "metadata": {},
   "source": [
    "## 1.1.8 AI에 대한 전망\n",
    "- 최근 매우 빠르게 발전해왔으며 연구 성과 대부분이 아직 적용되지 않음\n",
    "- 1995년 인터넷이 미래에 미칠 영향을 믿기 힘들었던 것처럼 AI도 그렇게 될 수 있음\n",
    "- 새로운 AI 겨울이 올 수도 있음\n",
    "- 단기간의 과대 선전을 믿지 말고 장기 비전을 믿어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0e76af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
