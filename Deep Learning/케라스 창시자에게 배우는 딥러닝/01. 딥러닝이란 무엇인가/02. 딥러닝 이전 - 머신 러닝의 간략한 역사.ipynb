{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa8243",
   "metadata": {},
   "source": [
    "# 1.2 딥러닝 이전: 머신 러닝의 간략한 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9449f",
   "metadata": {},
   "source": [
    "## 1.2.1 확률적 모델링\n",
    "- **확률적 모델링**(probabilistic modeling) : 통계학 이론을 데이터 분석에 응용한 것으로 대표적으로 나이브 베이즈(Naive Bayes) 알고리즘이 있음\n",
    "    - 나이브 베이즈 : 입력 데이터의 특성이 모두 독립적이라고 가정한(순진한; Naive) 베이즈 정리(Bayes' Theorem)을 적용한 머신 러닝 분류 알고리즘\n",
    "        - 컴퓨터가 등장하기 전 1950년대 수작업으로 적용\n",
    "- **로지스틱 회귀**(logistic regression) : 분류 알고리즘으로 컴퓨터보다 훨씬 오래 전부터 있었으나 간단하고 다목적으로 활용할 수 있어 지금까지 유용하게 쓰이는 알고리즘\n",
    "    - 분류 작업에 대한 감을 빠르게 얻기 위해 데이터셋에 적용할 첫 번째 알고리즘으로 선택하는 경우가 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0cec99",
   "metadata": {},
   "source": [
    "## 1.2.2 초창기 신경망\n",
    "- 1950년대 연구되기 시작하였으나 대규모 신경망을 훈련시킬 수 있는 효과적인 방법을 오랜 기간 동안 찾지 못하여 본격적으로 시작되기까지 오래 걸림\n",
    "- 1980년대 중반 역전파 알고리즘을 재발견, 신경망에 적용하며 상황이 변화\n",
    "    - 역전파 알고리즘 : 경사 하강법 최적화를 사용하여 연쇄적으로 변수가 연결된 연산을 훈련하는 방법\n",
    "- 성공적인 첫 번째 신경망 애플리케이션 : 1989년 벨 연구소(Bell Labs)에서 얀 르쿤(Yann LeCun)은 초창기 합성곱 신경망(Convolution neural network)과 역전파를 연결하여 손글씨 숫자 이미지 분류하는 문제에 적용\n",
    "    - **LeNet**이라 부르며 1990년대 미국 우편 서비스에 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1077e9d",
   "metadata": {},
   "source": [
    "## 1.2.3 커널 방법\n",
    "- 1990년대 LeNet이 성공하며 신경망이 관심을 얻었지만 **커널 방법**(Kernel method)가 나오며 잊혀짐\n",
    "- 분류 알고리즘의 한 종류이며 **서포트 벡터 머신**(Support Vector Machine; SVM)이 가장 유명\n",
    "    - 현대적인 SVM 공식은 1990년대 초 벨 연구소의 블라드미르 바프닉(Vladimir Vapnik)과 코리나 코르테스(Corinna Cortes)에 의해 개발, 1995년에 공개\n",
    "    - 오래된 선형 공식은 1963년 바프닉과 알렉세이 체르보넨키스(Alexey Chervonenkis)가 만들고 공개\n",
    "- SVM : 다른 범주에 속한 그룹 사이에 좋은 **결정 경계**(decision boundary)를 찾는 것\n",
    "    - 결정 경계를 찾는 과정\n",
    "        1. 결정 경계가 하나의 초평면(hyperplane)으로 표현될 수 있는 새로운 고차원 표현으로 데이터를 매핑\n",
    "        2. 초평면과 각 클래스의 가장 가까운 데이터 포인트 사이의 거리가 최대가 되는 최선의 결정 경계(하나의 분할 초평면)을 찾음\n",
    "            - 이 단계를 **마진 최대화**(maximizing the margin)라고 부름\n",
    "- 이론상으로 좋아 보이지만 실제 컴퓨터로 구현하기 어려운 경우가 많음\n",
    "- 그래서 **커널 기법**(kernel trick)이 등장\n",
    "    - **커널 함수**(kernel function)을 사용하여 새로운 공간에서의 두 데이터 포인트 사이의 거리를 계산할 수만 있으면 됨\n",
    "        - 데이터로 학습할 수 없고 직접 만들어야함\n",
    "- 수학적으로 깊게 분석하기 용이하여 이론을 이해하고 설명하기 쉬움\n",
    "- 그러나 대용량 데이터셋에 확장되기 어렵고 이미지 분류 등 지각 관련 문제에서 좋은 성능을 내지 못함\n",
    "- **특성 공학**(feature engineering)으로 SVM을 적용하기 전 수동으로 유용한 표현을 추출해야 하는데 매우 어렵고 불안정함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f5fe3",
   "metadata": {},
   "source": [
    "## 1.2.4 결정 트리, 랜덤 포레스트, 그래디언트 부스팅\n",
    "- **결정 트리**(decision tree) : 플로차트(flowchart) 같은 구조를 가지고 입력 데이터 포인트를 분류하거나 출력 값을 예측\n",
    "- **랜덤 포레스트**(Random Forest) 알고리즘 : 서로 다른 결정 트리를 많이 만들고 그 출력을 앙상블하는 방법을 사용하여 안정적이고 실전에서 유용\n",
    "    - 얕은 학습의 알고리즘 중 거의 항상 두 번째로 가장 좋음\n",
    "    - 2010년 머신 러닝 경연 웹 사이트 캐글이 시작되었을 때부터 선호되는 알고리즘\n",
    "- **그래디언트 부스팅 머신**(gradient boosting machine)이 2014년에 나오며 그 뒤를 이어받았으며 이전 모델에서 놓친 데이터 포인트를 보완하는 새로운 모델을 반복적으로 훈련함으로써 머신 러닝 모델을 향상하는 방법인 **그래디언트 부스팅**(gradient boosting)을 사용\n",
    "    - 지각에 관련되지 않은 데이터를 다루기 위한 곳에 딥러닝을 제외하면 가장 많이 쓰임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d738cbd",
   "metadata": {},
   "source": [
    "## 1.2.5 다시 신경망으로\n",
    "- 토론토 대학의 제프리 힌튼(Geoffrey Hinton), 몬트리올 대학의 요슈아 벤지오(Yoshua Bengio), 뉴욕 대학의 얀 르쿤, 스위스의 IDSIA가 성과를 내기 시작\n",
    "- 2011년 IDSIA의 댄 크리슨(Dan Ciresan)이 GPU로 훈련된 심층 신경망(deep neural network)으로 학술 이미지 분류 대회에서 우승한 것이 시작\n",
    "- 2012년 이미지 분류 대회인 ImageNet에 힌튼 팀이 등장하면서 분수령이 됨\n",
    "    - 1400만개의 이미지를 훈련시킨 후 고해상도 컬러 이미지를 1000개의 범주로 분류해야 함\n",
    "    - 2011년 전통적 방식을 사용한 우승 모델의 상위 5개 예측 정확도가 74.3%\n",
    "    - 2012년 제프리 힌튼과 알렉스 크리체브스키(Alex Krizhevsky)가 이끄는 팀이 정확도 83.6%로 향상\n",
    "- 이후 매년 심층 합성곱 신경망(deep convolution neural network; ConvNet)이 우승\n",
    "    - 2015년 96.4%의 정확도를 달성하여 완전히 해결된 것으로 간주\n",
    "- 자연어 처리(natural language processing) 등 다른 종류의 문제에도 적용되며 SVM과 결정 트리를 완전히 대체하고 있음\n",
    "- 유럽 입자 물리 연구소(European Organization for Nuclear Research; CERN)는 대형 강입자 충돌기(Large Hadron Collider; LHC)에 있는 ATLAS 감지기에서 얻은 입자 데이터를 분석하기 위해 결정 트리 기반 알고리즘을 사용해왔으나 최근 연구는 케라스(Keras) 기반의 심층 신경망을 적용하기 시작함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d522b",
   "metadata": {},
   "source": [
    "## 1.2.6 딥러닝의 특징\n",
    "- 특성 공학을 완전히 자동화하기 때문에 문제를 해결하기 쉽게 만들어 주는 것이 딥러닝이 빠르게 확산된 주된 요인\n",
    "- 얕은 학습 방법을 연속적으로 표현하면 각 층의 효과는 빠르게 줄어들기 때문에 사용할 수 없음\n",
    "- 딥러닝의 변환 능력은 모든 층을 동시에 공동으로 학습하기 때문에 얕은 학습 모델보다 강력함\n",
    "- **층을 거치면서 점진적으로 더 복잡한 표현이 만들어진다**\n",
    "- **점진적인 중간 표현이 공동으로 학습된다**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251fc87",
   "metadata": {},
   "source": [
    "## 1.2.7 머신 러닝의 최근 동향\n",
    "- 캐글의 머신 러닝 강연을 살펴보는 것으로 최근 동향을 알 수 있음\n",
    "- 2016, 2017년에는 그래디언트 부스팅과 딥러닝이 주류\n",
    "    - 구조적인 데이터인 경우 XGBoost 라이브러리 이용\n",
    "        - 데이터 과학 분야에서 잘 쓰이는 언어인 Python과 R을 지원\n",
    "    - 이미지 분류 같은 지각 관련 문제는 딥러닝 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ef926",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
