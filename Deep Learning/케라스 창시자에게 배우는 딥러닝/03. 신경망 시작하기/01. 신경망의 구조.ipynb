{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5466a920",
   "metadata": {},
   "source": [
    "# 3.1 신경망의 구조\n",
    "- **네트워크(또는 모델)**를 구성하는 **층**\n",
    "- **입력 데이터**와 그에 상응하는 **타깃**\n",
    "- 학습에 사용할 피드백 신호를 정의하는 **손실 함수**\n",
    "- 학습 진행 방식을 결정하는 **옵티마이저**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab47da5",
   "metadata": {},
   "source": [
    "## 3.1.1 층: 딥러닝의 구성 단위\n",
    "- 대부분의 층의 경우 **가중치**를 가짐 (Flatten, Pooing, Dropout 등을 제외)\n",
    "- 단순한 2D 텐서 데이터는 **완전 연결 층**(fully connected layer)이나 **밀집 층**(dense layer)이라고도 불리는 **밀집 연결 층**(densely connected layer)에 의해 처리되는 경우가 많음\n",
    "- 3D 텐서 시퀀스 데이터는 LSTM 같은 **순환 층**(recurrent layer)에 의해 처리\n",
    "- 4D 텐서 이미지 데이터는 2D **합성곱 층**(convolution layer)에 의해 처리\n",
    "- 케라스에서는 호환 가능한 층들을 엮어 데이터 변환 파이프라인(pipeline)을 구성함으로써 딥러닝 모델을 만듦\n",
    "- **층 호환성**(layer compatibility) : 각 층이 특정 크기의 입력 텐서만 받고 특정 크기의 출력 텐서를 반환\n",
    "```python\n",
    "model.add(layers.Dense(32, input_shape=(784, )))\n",
    "model.add(layers.Dense(10))\n",
    "```\n",
    "- 모델에 추가된 층을 자동으로 상위 층의 크기에 맞춰주기 때문에 호환성을 걱정하지 않아도 됨\n",
    "    - 두 번째 층에 input_shape 매개변수를 지정하지 않은 대신 앞선 층의 출력 크기를 입력 크기로 자동으로 채택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec32a83d",
   "metadata": {},
   "source": [
    "## 3.1.2 모델: 층의 네트워크\n",
    "- 딥러닝 모델은 층으로 만든 비순환 유향 그래프(Directed Acyclic Graph; DAG)\n",
    "- 하나의 입력을 하나의 출력으로 매핑하는 층을 순서대로 쌓는 것\n",
    "- 다양한 네트워크 구조\n",
    "    - 가지(branch)가 2개인 네트워크\n",
    "    - 출력이 여러 개인 네트워크\n",
    "    - 인셉션(Inception) 블록\n",
    "- 네트워크 구조는 **가설 공간**(hypothesis space)을 정의\n",
    "    - 네트워크 구조를 선택함으로써 **가능성 있는 공간**(가설 공간)을 입력 데이터에서 출력 데이터로 매핑하는 일련의 특정 텐서 연산으로 제한\n",
    "- 딱 맞는 네트워크 구조를 찾아내는 것은 과학보다 예술에 가까움\n",
    "- 신뢰할만한 모범적인 사례와 원칙이 있으나 연습을 해야만 적절한 신경망을 설계할 수 있는 기술을 갖추게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ff6c7",
   "metadata": {},
   "source": [
    "## 3.1.3 손실 함수와 옵티마이저: 학습 과정을 조절하는 열쇠\n",
    "- **손실 함수**(loss function)(**목적 함수**(objective function)) : 훈련하는 동안 최소화될 값\n",
    "- **옵티마이저**(optimizer) : 손실 함수를 기반으로 네트워크가 어떻게 업데이트될지 결정, SGD를 구현\n",
    "- 여러 개의 출력을 내는 신경망은 여러 개의 손실 함수를 가질 수 있음 (출력당 하나씩)\n",
    "- 경사 하강법 과정은 하나의 스칼라 손실 값을 기준으로 함\n",
    "    - 손실이 여러 개인 네트워크에서는 모든 손실이 (평균을 내서) 하나의 스칼라 양으로 합쳐짐\n",
    "- 올바른 손실 함수를 선택하는 것이 중요하며, 간단한 지침이 있음\n",
    "    - 2개 클래스가 있는 분류 문제에는 이진 크로스엔트로피(binary crossentropy)\n",
    "    - 여러 개의 클래스가 있는 분류 문제에는 범주형 크로스엔트로피(categorical crossentropy)\n",
    "    - 회귀 문제에는 평균 제곱 오차\n",
    "    - 시퀀스 학습 문제에는 CTC(Connection Temporal Classification) 등을 사용 (음성 인식, 필기 인식처럼 입력에 레이블 할당 위치를 정하기 어려운 연속적인 시퀀스를 다루는 문제에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184e04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
