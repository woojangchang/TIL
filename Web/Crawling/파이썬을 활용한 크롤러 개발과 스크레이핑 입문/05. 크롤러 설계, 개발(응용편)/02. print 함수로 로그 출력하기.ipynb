{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d1fc98",
   "metadata": {},
   "source": [
    "# 02. print 함수로 로그 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c3d958",
   "metadata": {},
   "source": [
    "- 로그 : 프로그램의 동작 상태 또는 이력이 출력된 텍스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef133d7",
   "metadata": {},
   "source": [
    "### 요청에 걸린 시간 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643e9e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 URL : http://example.com/1.page, HTTP 상태 : 404, 처리 시간(초) : 0.289719\n",
      "페이지 URL : http://example.com/2.page, HTTP 상태 : 404, 처리 시간(초) : 0.275996\n",
      "페이지 URL : http://example.com/3.page, HTTP 상태 : 404, 처리 시간(초) : 0.311603\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "PAGE_URL_LIST = [\n",
    "    'http://example.com/1.page',\n",
    "    'http://example.com/2.page',\n",
    "    'http://example.com/3.page',\n",
    "]\n",
    "\n",
    "for page_url in PAGE_URL_LIST:\n",
    "    res = requests.get(page_url, timeout=30)\n",
    "    print(\n",
    "        f'페이지 URL : {page_url}, HTTP 상태 : {res.status_code}, 처리 시간(초) : {res.elapsed.total_seconds()}'\n",
    "    )\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbe2b6",
   "metadata": {},
   "source": [
    "## 로그 출력과 관련된 다양한 개선이 필요한 이유\n",
    "- 매번 로그를 출력하면 수많은 출력 속에서 오류 로그를 찾기 힘듬\n",
    "- `python cralwer.py | tee -a crawler.log` 명령어를 통해 로그를 표준 출력과 파일에 동시에 출력할 수 있음\n",
    "- 아래 코드는 `requests.get()` 부분에서 오류가 일어나면 프로그램이 종료되어 open으로 열었던 파일이 close 되지 않아 버그가 발생할 수 있다는 문제점이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "PAGE_URL_LIST = [\n",
    "    'http://example.com/1.page',\n",
    "    'http://example.com/2.page',\n",
    "    'http://example.com/3.page',\n",
    "]\n",
    "\n",
    "def fetch_pages():\n",
    "    '''\n",
    "    페이지의 내용을 추출\n",
    "    '''\n",
    "    # 처리 기록 전용 로그 파일을 append 모드로 열기\n",
    "    f_info_log = open('crawler_info.log', 'a')\n",
    "    \n",
    "    # 오류 기록 전용 로그 파일을 append 모드로 열기\n",
    "    f_error_log = open('crawler_error.log', 'a')\n",
    "    \n",
    "    # 추출 내용을 저장할 딕셔너리\n",
    "    page_contents = {}\n",
    "    \n",
    "    # 터미널에 처리 시작을 출력하고 로그 파일에도 메시지를 출력\n",
    "    msg = '크롤링을 시작합니다.\\n'\n",
    "    print(msg)\n",
    "    f_info_log.write(msg)\n",
    "    \n",
    "    for page_url in PAGE_URL_LIST:\n",
    "        r = requests.get(page_url, timeout=30)\n",
    "        try:\n",
    "            r.raise_for_status() # 응답에 문제가 생기면 예외를 발생\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # requests와 관련된 예외가 발생하면 터미널과 오류 로그에 오류를 출력\n",
    "            msg = f\"[ERROR] {e}\\n\"\n",
    "            print(msg)\n",
    "            f_error_log.write(msg)\n",
    "            continue # 예외가 발생하면 반복을 중지하는 것이 아닌 건너뛰기\n",
    "            \n",
    "        # 정상적으로 내용을 추출했다면 딕셔너리에 내용 저장\n",
    "        page_contents[page_url] = r.text\n",
    "        time.sleep(1)\n",
    "        \n",
    "    f_info_log.close()\n",
    "    f_error_log.close()\n",
    "    \n",
    "    return page_contents\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    page_contents = fetch_pages()\n",
    "    f_page_contents = open('page_contents.json', 'w')\n",
    "    json.dump(page_contents, f_page_contents, ensure_ascii=False)\n",
    "    f_page_contents.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0078003",
   "metadata": {},
   "source": [
    "- 아래 코드처럼 open, close 대신 with 문을 통해 close 메서드 누수를 막을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "PAGE_URL_LIST = [\n",
    "    'http://example.com/1.page',\n",
    "    'http://example.com/2.page',\n",
    "    'http://example.com/3.page',\n",
    "]\n",
    "\n",
    "def fetch_pages():\n",
    "    '''\n",
    "    페이지의 내용을 추출\n",
    "    '''\n",
    "    # 처리 기록 전용 로그 파일과 오류 기록 전용 로그 파일을 append 모드로 열기\n",
    "    with open('crawler_info.log', 'a') as f_info_log, \\\n",
    "         open('crawler_error.log', 'a') as f_error_log:\n",
    "    \n",
    "        # 추출 내용을 저장할 딕셔너리\n",
    "        page_contents = {}\n",
    "\n",
    "        # 터미널에 처리 시작을 출력하고 로그 파일에도 메시지를 출력\n",
    "        msg = '크롤링을 시작합니다.\\n'\n",
    "        print(msg)\n",
    "        f_info_log.write(msg)\n",
    "\n",
    "        for page_url in PAGE_URL_LIST:\n",
    "            r = requests.get(page_url, timeout=30)\n",
    "            try:\n",
    "                r.raise_for_status() # 응답에 문제가 생기면 예외를 발생\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                # requests와 관련된 예외가 발생하면 터미널과 오류 로그에 오류를 출력\n",
    "                msg = f\"[ERROR] {e}\\n\"\n",
    "                print(msg)\n",
    "                f_error_log.write(msg)\n",
    "                continue # 예외가 발생하면 반복을 중지하는 것이 아닌 건너뛰기\n",
    "\n",
    "            # 정상적으로 내용을 추출했다면 딕셔너리에 내용 저장\n",
    "            page_contents[page_url] = r.text\n",
    "            time.sleep(1)\n",
    "\n",
    "        return page_contents\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    page_contents = fetch_pages()\n",
    "    f_page_contents = open('page_contents.json', 'w')\n",
    "    json.dump(page_contents, f_page_contents, ensure_ascii=False)\n",
    "    f_page_contents.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
